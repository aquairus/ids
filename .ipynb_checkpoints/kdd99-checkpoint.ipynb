{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_palette('deep', desat=.6)\n",
    "sns.set_context(rc={'figure.figsize': (8, 5) } )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"data/kddcup_data_10_percent.txt\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([     0,      1,      2,      3,      4,      5,      6,      7,\n",
       "                 8,      9,\n",
       "            ...\n",
       "            494010, 494011, 494012, 494013, 494014, 494015, 494016, 494017,\n",
       "            494018, 494019],\n",
       "           dtype='int64', length=494020)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'0', u'tcp', u'http', u'SF', u'181', u'5450', u'0.1', u'0.2', u'0.3',\n",
       "       u'0.4', u'0.5', u'1', u'0.6', u'0.7', u'0.8', u'0.9', u'0.10', u'0.11',\n",
       "       u'0.12', u'0.13', u'0.14', u'0.15', u'8', u'8.1', u'0.00', u'0.00.1',\n",
       "       u'0.00.2', u'0.00.3', u'1.00', u'0.00.4', u'0.00.5', u'9', u'9.1',\n",
       "       u'1.00.1', u'0.00.6', u'0.11', u'0.00.7', u'0.00.8', u'0.00.9',\n",
       "       u'0.00.10', u'0.00.11', u'normal.'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'udp': 2, 'icmp': 0, 'tcp': 1}\n",
      "{'domain': 10, 'netbios_ssn': 35, 'telnet': 56, 'Z39_50': 2, 'smtp': 50, 'gopher': 20, 'private': 45, 'echo': 12, 'shell': 49, 'red_i': 46, 'eco_i': 13, 'sunrpc': 53, 'ftp_data': 19, 'urh_i': 60, 'pm_dump': 41, 'pop_3': 43, 'pop_2': 42, 'systat': 55, 'ftp': 18, 'sql_net': 51, 'whois': 65, 'netbios_dgm': 33, 'efs': 15, 'remote_job': 47, 'daytime': 8, 'ntp_u': 39, 'uucp': 62, 'finger': 17, 'ldap': 28, 'netbios_ns': 34, 'kshell': 27, 'iso_tsap': 25, 'ecr_i': 14, 'nntp': 38, 'printer': 44, 'domain_u': 11, 'uucp_path': 63, 'courier': 5, 'exec': 16, 'time': 59, 'netstat': 36, 'auth': 3, 'rje': 48, 'hostnames': 21, 'link': 29, 'ssh': 52, 'http_443': 23, 'csnet_ns': 6, 'X11': 1, 'IRC': 0, 'tftp_u': 57, 'login': 30, 'supdup': 54, 'name': 32, 'nnsp': 37, 'mtp': 31, 'http': 22, 'bgp': 4, 'ctf': 7, 'klogin': 26, 'vmnet': 64, 'tim_i': 58, 'discard': 9, 'imap4': 24, 'other': 40, 'urp_i': 61}\n",
      "{'OTH': 0, 'RSTR': 4, 'S3': 8, 'S2': 7, 'S1': 6, 'S0': 5, 'RSTOS0': 3, 'REJ': 1, 'SH': 10, 'RSTO': 2, 'SF': 9}\n",
      "{0: 0, 1: 1}\n",
      "{0: 0, 1: 1}\n",
      "{0: 0, 1: 1}\n",
      "{0: 0, 1: 1, 2: 2}\n",
      "{0: 0}\n",
      "{0: 0, 1: 1}\n"
     ]
    }
   ],
   "source": [
    "vectorize_map={}\n",
    "select_feature=[2, 3 ,4 ,7  ,12 ,14 ,15 ,21 ,22]\n",
    "for i in select_feature:\n",
    "    select_key=df.columns[i-1]\n",
    "    tcp_dict=dict(enumerate(np.unique(df[select_key])))\n",
    "    vectorize_map[i]=dict((v,k) for k,v in tcp_dict.iteritems())\n",
    "\n",
    "for i in  select_feature:\n",
    "    print vectorize_map[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def normal_or_not(text):\n",
    "    if text==\"normal.\":\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "washed_df=pd.DataFrame()    \n",
    "\n",
    "washed_df[0]=df['normal.'].map(normal_or_not)\n",
    "for i in select_feature:\n",
    "    key=df.columns[i-1]\n",
    "#     print key\n",
    "    washed_df[i]=df[key].map(vectorize_map[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97277\n",
      "494020\n",
      "0.196909032023\n"
     ]
    }
   ],
   "source": [
    "print len(washed_df.loc[washed_df[0]==1])\n",
    "print len (washed_df)\n",
    "print len(washed_df.loc[washed_df[0]==1])/ float(len (washed_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier,AdaBoostClassifier\n",
    "forest = RandomForestClassifier(n_estimators=10)\n",
    "ada=AdaBoostClassifier()\n",
    "gdbt=GradientBoostingClassifier()\n",
    "\n",
    "train_data = washed_df.values\n",
    "forest = forest.fit(train_data[0::,1::],train_data[0::,0] )\n",
    "\n",
    "\n",
    "\n",
    "from sklearn import cross_validation\n",
    "forest_scores = cross_validation.cross_val_score(forest,train_data[0::,1::], train_data[0::,0],cv=5)\n",
    "\n",
    "\n",
    "ada_scores = cross_validation.cross_val_score(ada,train_data[0::,1::], train_data[0::,0],cv=5)\n",
    "\n",
    "gdbt_scores = cross_validation.cross_val_score(gdbt,train_data[0::,1::], train_data[0::,0],cv=5)\n",
    " \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print forest_scores.mean()\n",
    "print ada_scores.mean()\n",
    "print gdbt_scores.mean()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "y_true = train_data[0::,0]\n",
    "y_scores = forest.predict_proba(train_data[0::,1::])\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(y_true, y_scores[0::,1])\n",
    "\n",
    "\n",
    "plt.plot( recall,precision)\n",
    "print metrics.auc(recall,precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(y_true, y_scores[0::,1])\n",
    "plt.plot( fpr, tpr)\n",
    "print metrics.auc(fpr, tpr)\n",
    "print forest.score(train_data[0::,0],y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
